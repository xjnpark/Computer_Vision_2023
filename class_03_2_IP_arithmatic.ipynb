{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ðŸ‘‰ class_03_2 IP Â» _Arithmetic Operations - Synthesizing, Blending, Masking & Reversing_ </center>\n",
    "\n",
    "# â–£ Arithmetic Operations on Images  \n",
    "\n",
    "Learn several arithmetic operations on images like addition, subtraction, bitwise operations etc.  \n",
    "You will learn these functions : \n",
    "* **cv2.add()**  \n",
    "* **cv2.addWeighted()** etc.  \n",
    "\n",
    "## â–¶ Image Addition  \n",
    "You can add two images by OpenCV function, cv2.add() or simply by numpy operation,   \n",
    "- res = img1 + img2.  \n",
    "\n",
    "Both images should be of same depth and type, or second image can just be a scalar value.  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.add(src1, src2, dst, mask, dtype):** \n",
    "\n",
    "~ Parameters:    \n",
    "* src1: 1st img\n",
    "* src2: 2nd img\n",
    "* dst(optional): output img\n",
    "* mask(optional): Computes only non-zero pixels with mask values\n",
    "* dtype(optional): output data type (dtype)\n",
    "\n",
    "### Note\n",
    "\n",
    "There is a difference between OpenCV addition and Numpy addition.  \n",
    "OpenCV addition is a saturated operation while Numpy addition is a modulo operation.\n",
    "\n",
    "For example, consider below sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    "print('Numpy add x+y = ', x+y ) # 250+10 = 260 % 256 = 4\n",
    "print('cv.add(x,y) = ', cv2.add(x,y) ) # 250+10 = 260 => 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be more visible when you add two images.  \n",
    "OpenCV function will provide a better result.  \n",
    "So always better stick to OpenCV functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Image Subtraction \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.subtract(src1, src2, dst, mask, dtype):** \n",
    "\n",
    "~ Parameters: same as the cv2.add() \n",
    "\n",
    "## â–¶ Image Multiply   \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.multiply(src1, src2, dst, scale, dtype):** \n",
    "\n",
    "~ Parameters:  \n",
    "    \n",
    "* scale(optional): multiple value  \n",
    "\n",
    "## â–¶ Image Divide  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.divide(src1, src2, dst, scale, dtype):** \n",
    "\n",
    "~ Parameters: same as the cv2.multiply()\n",
    "\n",
    "## â–¶ Examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arithmatic.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = np.uint8([[200, 50]]) \n",
    "b = np.uint8([[100, 100]])\n",
    "\n",
    "add1 = a + b  # NumPy operation\n",
    "sub1 = a - b\n",
    "mult1 = a * 2\n",
    "div1 = a / 3\n",
    "\n",
    "add2 = cv2.add(a, b)  # OpenCV API operation\n",
    "sub2 = cv2.subtract(a, b)\n",
    "mult2 = cv2.multiply(a , 2)\n",
    "div2 = cv2.divide(a, 3)\n",
    "\n",
    "print('a = ', a, 'b = ' , b)\n",
    "print()\n",
    "print('np a + b = ', add1, ',                  cv2.add(a, b) = ' , add2)\n",
    "print('np a - b = ', sub1, ',                  cv2.subtract(a, b) = ', sub2)\n",
    "print('np a * 2 = ', mult1, ',                  cv2.multiply(a, 2) =', mult2)\n",
    "print('np a / 3 = ', div1, ',  cv2.divide(a, 3) = ', div2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the numpy calculation results and the calculation results using the OpenCV calculation function are different.  \n",
    "- The left side is the result of calculation with numpy, \n",
    "- and the right side is the result of calculation with the OpenCV function.\n",
    "\n",
    ">- 200 + 100 = 300, which exceeds 255. The value range of the unit8 type is 0 to 255, so values exceeding 255 are counted from 0 again.\n",
    ">- Calculating 200 + 100 with numpy is 300, which is 300 - 256 = 44.   \n",
    "\n",
    "- On the other hand, if you use the cv2.add() function, \n",
    "\n",
    ">- all values exceeding 255 will be returned as 255.\n",
    ">- 50 + 100 = 150, which has the same result whether numpy operation or cv2.add() operation. Because 150 does not exceed 255.  \n",
    ">- Similarly, 50 - 100 = -50, but the result of numpy operation is 206. Because -50 + 256 = 206.  \n",
    "\n",
    "- The result of calculation with cv2.subtract() is 0.   \n",
    "\n",
    ">- This is because OpenCV returns all values less than 0 as 0.  \n",
    "\n",
    "- Multiplication and division operations also do not take values greater than 255 or less than 0, and do not have decimal points.  \n",
    "\n",
    "When you pass a third parameter to the cv2.add() function, it assigns the sum of the first and second parameters to the third parameter.  \n",
    "\n",
    "Therefore, the results of the three codes below are the same:\n",
    "- c = cv2.add(a, b): Add a and b and assign to c\n",
    "- c = cv2.add(a, b, None): Add a and b and assign to None\n",
    "- cv2.add(a, b, c): Add a and b and assign to c  \n",
    "    \n",
    "â€» If a numpy array is passed to the fourth parameter, mask, the operation is performed only on pixels at positions (indexes) where the mask value is not 0.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arithmatic_mask and accumulating computation\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2]], dtype=np.uint8) \n",
    "b = np.array([[10, 20]], dtype=np.uint8)\n",
    "mask = np.array([[1, 0]], dtype=np.uint8) \n",
    "c1 = cv2.add(a, b, None, mask) # mask value (1, 0)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = cv2.add(a, b, b.copy(), mask) # adds only the first element of a and b. the third parameter is b.copy() = [10, 20], leaving the second element of b alone. So the result is [[11, 20]].\n",
    "print(c2, b.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = cv2.add(a, b, b, mask) # adds only the first element of a and b -> 3rd b = (11, 0) -> b with mask(11,20) \n",
    "print(c3, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add only the first elements of a and b and apply to the first element of b,\n",
    "Leave the second element of b alone. So the results [[11, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"./images/practice_img/pencil_small.jpg\")\n",
    "number1 = np.ones_like(src) * 127 # grey(127, 127, 127) \n",
    "number2 = np.ones_like(src) * 2   # black(2, 2, 2) ì‚¬ìš©\n",
    "img = src.copy()\n",
    "add = cv2.add(src, number1)\n",
    "sub = cv2.subtract(src, number1)\n",
    "mul = cv2.multiply(src, number2)\n",
    "div = cv2.divide(src, number2)\n",
    "\n",
    "src = np.concatenate((src, src, src, src), axis = 1)\n",
    "number = np.concatenate((number1, number1, number2, number2), axis = 1)\n",
    "dst = np.concatenate((add, sub, mul, div), axis = 1)\n",
    "\n",
    "dst = np.concatenate((src, number, dst), axis = 0)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "titles = ['original', 'add+127', 'sub-127','mul*2','div /2']\n",
    "images = [img, add, sub, mul, div ]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(titles[i]), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Image Compare  \n",
    "\n",
    "There is no subtraction taking place only comparison  \n",
    "cv2.compare performs an element-wise comparison. In simple words, given the following instance:  \n",
    "- **cv2.compare(A, B, cv2.CMP_GT)**  \n",
    "\n",
    "every element in array A is compared with every element in array B.   \n",
    "The flag cv2.CMP_GT is used to check whether the element in A is greater than of B in each comparison. It returns another array containing 0 and 255; where\n",
    ">- 0 -> element in A is not greater than that in B  \n",
    ">- 255 -> element in A is greater than that in B  \n",
    "\n",
    "OpenCV limits the range between 0-255 internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"./images/practice_img/pencil_small.jpg\")\n",
    "number = np.ones_like(src) * 127\n",
    "img = src.copy()\n",
    "_max = cv2.max(src, number) \n",
    "_min = cv2.min(src, number) \n",
    "_abs = cv2.absdiff(src, number) \n",
    "compare1 = cv2.compare(src, number, cv2.CMP_GT) #  src > number True : 255,  False: 0\n",
    "# compare2 = cv2.compare(src, number, cv2.CMP_LT) #  src < number\n",
    "\n",
    "src = np.concatenate((src, src, src, src), axis = 1)\n",
    "number = np.concatenate((number, number, number, number), axis = 1)\n",
    "dst = np.concatenate((_max, _min, _abs, compare1), axis = 1)\n",
    "\n",
    "dst = np.concatenate((src, number, dst), axis = 0)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "titles = ['original', '_max>127', '_min<127','_abs diff', 'compare1:GT', 'compare2:LT']\n",
    "images = [img, _max, _min, _abs, compare1, compare2 ]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(titles[i]), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The maximum (minimum) value function calculates the maximum (minimum) value for each element of the two images.\n",
    "- If the comparison result is True, change the value of the element to 255,   \n",
    "- and if the comparison result is False, change the value of the element to 0.\n",
    "\n",
    "### â— flags  \n",
    "\n",
    "Flag   | Meaning   \n",
    "-------|--------\n",
    "cv2.CMP_EQ|src = number\n",
    "cv2.CMP_NE|src â‰  number\n",
    "cv2.CMP_GT|src > number\n",
    "cv2.CMP_GE|src â‰§ number\n",
    "cv2.CMP_LT|src < number\n",
    "cv2.CMP_LE|src â‰¦ number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When compositing two images, neither the sum of numpy nor the cv2.add() function seen above will give you good results.\n",
    "If you perform numpy's summation, if the pixel value is greater than 255, the image will be close to black because it will only have an excess value.\n",
    "\n",
    "For example, if you add 150 and 180 together, you get 330, so the final result is 74, which is the excess value at 255. This will cause some areas to be overwhelmed.\n",
    "On the other hand, if you do the cv2.add() operation, most of the pixel values will be close to 255. Thus, the image will be white overall.\n",
    "\n",
    "The code below shows such an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending_simple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/wing_wall.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/yate.jpg')\n",
    "\n",
    "print(img1.shape, img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img3 = img1 + img2  \n",
    "img4 = cv2.add(img1, img2) \n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "imgs = {'img1':img1, 'img2':img2, 'img1+img2': img3, 'cv.add(img1, img2)': img4}\n",
    "\n",
    "for i, (k, v) in enumerate(imgs.items()):\n",
    "    plt.subplot(2,2, i + 1)\n",
    "    plt.imshow(v[:,:,::-1])\n",
    "    plt.title(k)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Weighted Image Blending  \n",
    "\n",
    "This is also image addition, but different weights(alpha) are given to images so that it gives a feeling of blending or transparency.  \n",
    "Images are added as per the equation below:  \n",
    "\n",
    "$$ g(x) = (1 - \\alpha)f_{0}(x) + \\alpha f_{1}(x) $$\n",
    "\n",
    "By varying $\\alpha$ from 0 $\\rightarrow$ 1, you can perform a cool transition between one image to another.  \n",
    "Here I took two images to blend them together.  \n",
    "First image is given a weight of 0.7 and second image is given 0.3.  \n",
    "cv2.addWeighted() applies following equation on the image.  \n",
    "\n",
    "$$ dst = \\alpha \\cdot img1 + \\beta \\cdot img2 + \\gamma $$\n",
    "\n",
    "Here $\\gamma$ is taken as zero.\n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **cv2.addWeight(img1, alpha, img2, beta, gamma)**  \n",
    "\n",
    "~ Parameters: \n",
    "    \n",
    "- img1, img2: imgs\n",
    "- alpha: weight value to img_1\n",
    "- beta: weight value to img_2 (1-alpha) \n",
    "- gamma: constant value, 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending_alpha.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.3 \n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/wing_wall.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/yate.jpg')\n",
    "\n",
    "blended = img1 * alpha + img2 * (1-alpha) # equation\n",
    "blended = blended.astype(np.uint8) \n",
    "cv2.imshow('img1 * alpha + img2 * (1-alpha)', blended)\n",
    "\n",
    "dst = cv2.addWeighted(img1, alpha, img2, (1-alpha), 0) # opencv\n",
    "cv2.imshow('cv2.addWeighted', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
    "axs[0].imshow(blended), axs[0].axis('off'), axs[0].set_title('np_blended')\n",
    "axs[1].imshow(dst), axs[1].axis('off'), axs[1].set_title('addWeighted')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Image Blending\n",
    "\n",
    "img1 = cv2.imread('./images/dogs/04.jpg')\n",
    "img2 = cv2.imread('./images/cats/cat.jpg')\n",
    "img2_resized = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "dst1 = cv2.addWeighted(img1,0.7,img2,0.3,0)\n",
    "dst2 = cv2.addWeighted(img1,0.3,img2,0.7,0)\n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(10,10))\n",
    "axs[0].imshow(img1), axs[0].axis('off'), axs[0].set_title('img1')\n",
    "axs[1].imshow(img2), axs[1].axis('off'), axs[1].set_title('img2')\n",
    "axs[2].imshow(dst1), axs[2].axis('off'), axs[2].set_title('0.7_img1+0.3_img2')\n",
    "axs[3].imshow(dst2), axs[3].axis('off'), axs[3].set_title('0.3_img1+0.7_img2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "img1 = cv2.imread('./images/ml.png')\n",
    "img2 = cv2.imread('./images/OIP.png')\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(5,5))\n",
    "axs[0].imshow(img1), axs[0].axis('off'), axs[0].set_title('Org_1')\n",
    "axs[1].imshow(img2), axs[1].axis('off'), axs[1].set_title('Org_2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape, img2.shape # check img size and make same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_resized = cv2.resize(img2, (img1.shape[1], img1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape, img2_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.addWeighted(img1,0.6,img2_resized,0.4,0)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(5,5))\n",
    "axs[0].imshow(img1), axs[0].axis('off'), axs[0].set_title('Org_1')\n",
    "axs[1].imshow(img2), axs[1].axis('off'), axs[1].set_title('Org_2')\n",
    "axs[2].imshow(dst), axs[2].axis('off'), axs[2].set_title('Adding 2 Imgs')\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.imshow(img2)\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Blending with Alpha Trackbar\n",
    "\n",
    "Moving the trackbar to adjust the alpha value to synthesize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending_alpha_trackbar.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "win_name = 'Alpha blending'     \n",
    "trackbar_name = 'fade'          \n",
    "\n",
    "def onChange(x):\n",
    "    alpha = x/100\n",
    "    dst = cv2.addWeighted(img1, 1-alpha, img2, alpha, 0) \n",
    "    cv2.imshow(win_name, dst)\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/man_face.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/lion_face.jpg')\n",
    "\n",
    "cv2.imshow(win_name, img1)\n",
    "cv2.createTrackbar(trackbar_name, win_name, 0, 100, onChange)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Bitwise arithmetics  \n",
    "\n",
    "Bitwise arithmetic helps with selective computations, such as selecting only certain regions or excluding only certain regions when compositing two images.   \n",
    "\n",
    "<img src = './images/practice_img/bitwise.jpeg' width=400 height=400> \n",
    "\n",
    "\n",
    " https://slideplayer.com/slide/5378944/  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    ">- cv2.bitwise_and(img1, img2, mask=None)  \n",
    ">- cv2.bitwise_or(img1, img2, mask=None)\n",
    ">- cv2.bitwise_xor(img1, img2, mask=None)  \n",
    ">- cv2.bitwise_not(img1, img2, mask=None)  \n",
    "\n",
    "~ Parameters:  \n",
    "\n",
    ">- img1, img2 : same shape imgs\n",
    ">- mask : calulate only not 0 pxls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitwise.py\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "img1 = np.zeros((200,400), dtype=np.uint8) # all black img\n",
    "img2 = np.zeros((200,400), dtype=np.uint8)\n",
    "img1[:, :200] = 255         # left half white(255), right half black(0)\n",
    "img2[100:200, :] = 255      # above half black(0), bottom half white(255)\n",
    "\n",
    "bitAnd = cv2.bitwise_and(img1, img2)\n",
    "bitOr = cv2.bitwise_or(img1, img2)\n",
    "bitXor = cv2.bitwise_xor(img1, img2)\n",
    "bitNot = cv2.bitwise_not(img1)\n",
    "\n",
    "imgs = {'img1':img1, 'img2':img2, 'and':bitAnd, 'or':bitOr, 'xor':bitXor, 'not(img1)':bitNot}\n",
    "for i, (title, img) in enumerate(imgs.items()):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    plt.title(title)\n",
    "    plt.imshow(img, 'gray')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is black, 255 is white.   \n",
    "- Substituting a boolean value is False for 0 and True for a non-zero value.   \n",
    "- Therefore, black is 0, which means False, and white is 255, which means True.   \n",
    "- Both values must be true in order for the AND operation of two values to be True.   \n",
    "- Therefore, after the AND operation, only the white part of img1 and img2 overlaps in white.\n",
    "\n",
    "    0ì€ ê²€ì€ìƒ‰, 255ì€ í°ìƒ‰ìž…ë‹ˆë‹¤.   \n",
    "    - ë¶ˆë¦¬ì–¸(boolean) ê°’ìœ¼ë¡œ ì¹˜í™˜í•˜ë©´ 0ì€ False, 0ì´ ì•„ë‹Œ ê°’ì€ Trueìž…ë‹ˆë‹¤.   \n",
    "    - ë”°ë¼ì„œ ê²€ì€ìƒ‰ì€ 0ì´ë¯€ë¡œ Falseë¥¼ ì˜ë¯¸í•˜ê³ , í°ìƒ‰ì€ 255ì´ë¯€ë¡œ Trueë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.   \n",
    "    - ë‘ ê°’ì˜ AND ì—°ì‚° ê²°ê³¼ Trueê°€ ë˜ê¸° ìœ„í•´ì„œëŠ” ë‘ ê°’ ëª¨ë‘ Trueì—¬ì•¼ í•©ë‹ˆë‹¤.   \n",
    "    - ë”°ë¼ì„œ AND ì—°ì‚° í›„ì—ëŠ” img1ê³¼ img2ì˜ í°ìƒ‰ ë¶€ë¶„ì´ ê²¹ì¹˜ëŠ” ê³³ë§Œ í°ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using bitwise operation to remove a part of an image into the desired shape\n",
    "ë¹„íŠ¸ì™€ì´ì¦ˆ ì—°ì‚°ìœ¼ë¡œ ì´ë¯¸ì§€ ì¼ë¶€ë¶„ì„ ì›í•˜ëŠ” ëª¨ì–‘ìœ¼ë¡œ ë–¼ì–´ë‚´ëŠ” ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â— Bitwise masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitwise_masking.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img = cv2.imread('./images/practice_img/eiffel_tower.jpg')\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)), plt.axis('off'), plt.title('img')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(img) # all 0 black img\n",
    "cv2.circle(mask, (400,200), 150, (255,255,255), -1) # mask area : 255 (white, filled circle)\n",
    "masked = cv2.bitwise_and(img, mask) # only the both area has pxl values : true\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('masked', masked)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "masked = cv2.cvtColor(masked, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "axs[0].imshow(img), axs[0].axis('off'), axs[0].set_title('original')\n",
    "axs[1].imshow(mask), axs[1].axis('off'), axs[1].set_title('mask')\n",
    "axs[2].imshow(masked), axs[2].axis('off'), axs[2].set_title('masked img')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Masked Blending Img \n",
    "\n",
    "Let's learn how to combine two images (4 channels) with a background and a foreground (the object image). \n",
    "\n",
    "â— Typically, one image is divided into a background and a foreground (the actual image, not the background). \n",
    "- For example, consider an image of a dog on green grass.   \n",
    "- The green grass is in the background, the dog is in the foreground.   \n",
    "- What if what we want is a puppy instead of green grass? \n",
    "- Only puppies should be extracted from the image. \n",
    "\n",
    "â— First of all, let's use an image with a transparent background and composit. \n",
    "- In the BGRA color format, A (alpha) is 0 for the background and A (alpha) is 255 for the foreground. \n",
    "- This is because A is transparent if it is 0, and it is opaque if it is 255.   \n",
    "- With BGRA, you can easily cut out the background. \n",
    "\n",
    "     â— ë°°ê²½ê³¼ ì „ê²½(ë°°ê²½ì´ ì•„ë‹Œ ì‹¤ì œ ì´ë¯¸ì§€)ì´ ìžˆëŠ” 4 ì±„ë„ì˜ ë‘ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤. \n",
    "    ì¼ë°˜ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ëŠ” ë°°ê²½ê³¼ ì „ê²½(ë°°ê²½ì´ ì•„ë‹Œ ì‹¤ì œ ì´ë¯¸ì§€)ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. \n",
    "    ì˜ˆë¥¼ ë“¤ì–´ í‘¸ë¥¸ ìž”ë””ì— ê°•ì•„ì§€ê°€ ìžˆëŠ” ì´ë¯¸ì§€ë¥¼ ìƒê°í•´ë´…ì‹œë‹¤. í‘¸ë¥¸ ìž”ë””ëŠ” ë°°ê²½ì´ê³ , ê°•ì•„ì§€ëŠ” ì „ê²½ìž…ë‹ˆë‹¤. \n",
    "    ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²Œ í‘¸ë¥¸ ìž”ë””ê°€ ì•„ë‹Œ ê°•ì•„ì§€ë¼ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”? \n",
    "    ì´ë¯¸ì§€ì—ì„œ ê°•ì•„ì§€ë§Œì„ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. \n",
    "\n",
    "    â€¢ ìš°ì„  ë°°ê²½ì´ íˆ¬ëª…í•œ ì´ë¯¸ì§€ë¥¼ í™œìš©í•˜ì—¬ í•©ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.   \n",
    "    â€¢ BGRA ìƒ‰ìƒ í˜•ì‹ìœ¼ë¡œ í‘œí˜„í•  ë•Œ, ë°°ê²½ì€ A(ì•ŒíŒŒ, alpha)ê°€ 0ì´ê³ , ì „ê²½ì€ A(ì•ŒíŒŒ)ê°€ 255ìž…ë‹ˆë‹¤.   \n",
    "    â€¢ Aê°€ 0ì´ë©´ íˆ¬ëª…í•˜ê³ , 255ë©´ ë¶ˆíˆ¬ëª…í•˜ê¸° ë•Œë¬¸ìž…ë‹ˆë‹¤. BGRAë¥¼ í™œìš©í•˜ë©´ ë°°ê²½ì„ ì†ì‰½ê²Œ ì˜¤ë ¤ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combine_rgba_mask.py íˆ¬ëª… ë°°ê²½ PNG íŒŒì¼ì„ ì´ìš©í•œ í•©ì„±\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_fg = cv2.imread('./images/practice_img/opencv_logo.png', cv2.IMREAD_UNCHANGED) # 4 chnl png file\n",
    "img_bg = cv2.imread('./images/practice_img/eiffel_tower.jpg')\n",
    "\n",
    "_, mask = cv2.threshold(img_fg[:,:,3], 1, 255, cv2.THRESH_BINARY) # cv2.threshold(img, threshold_value, value, flag)\n",
    "# If it is greater than threshold, it is value, or replace it with 0.\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "img_fg = cv2.cvtColor(img_fg, cv2.COLOR_BGRA2BGR) \n",
    "h, w = img_fg.shape[:2]\n",
    "roi = img_bg[10:10+h, 10:10+w ]\n",
    "\n",
    "masked_fg = cv2.bitwise_and(img_fg, img_fg, mask=mask) \n",
    "masked_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "added = masked_fg + masked_bg      \n",
    "img_bg[10:10+h, 10:10+w] = added\n",
    "\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('mask_inv', mask_inv)\n",
    "cv2.imshow('masked_fg', masked_fg)\n",
    "cv2.imshow('masked_bg', masked_bg)\n",
    "cv2.imshow('added', added)\n",
    "cv2.imshow('result', img_bg)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig, axs = plt.subplots(1,5,figsize=(15,10))\n",
    "axs[0].imshow(mask), axs[0].axis('off'), axs[0].set_title('mask')\n",
    "axs[1].imshow(mask_inv,cmap='gray'), axs[1].axis('off'), axs[1].set_title('mask_inv')\n",
    "axs[2].imshow(masked_fg), axs[2].axis('off'), axs[2].set_title('masked_fg')\n",
    "axs[3].imshow(masked_bg), axs[3].axis('off'), axs[3].set_title('masked_bg')\n",
    "axs[4].imshow(added), axs[4].axis('off'), axs[4].set_title('added')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img_bg, cv2.COLOR_BGR2RGB)),plt.axis('off'), plt.title('result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â— cv2.threshod(img_fg[:, :, 3], 1, 255, cv2.THRESH_BINARY)\n",
    "- cv2.threshold(img, threshold_value, value, flag)\n",
    "- If it is greater than threshold, it is value, or replace it with 0.\n",
    "- Create a mask that separates the background from the foreground\n",
    "\n",
    "â— The image that says OpenCV has a transparent background.   \n",
    "- Therefore, the background part has an A value of 0 in BRGA. \n",
    "- On the other hand, the foreground part, not the background, is not a zero.   \n",
    "- So, if A is more than 1, it will be 255, and if it is less than 1, it will be 0,   \n",
    "- and the background will be black and the foreground will be white. \n",
    "\n",
    "â— mask_inv = cv2.bitwise_not (mask), so mask_inv is the opposite of mask.\n",
    "- That is, the background is white and the foreground is black.   \n",
    "- These two masks were used to composite the Paris image and the OpenCV image\n",
    "\n",
    "    â— cv2.threshold(img, threshold_value, value, flag)ë¡œ ì „ê²½ì„ ë¶„ë¦¬í•˜ëŠ” ë§ˆìŠ¤í¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.  \n",
    "    - OpenCVë¼ê³  ì“°ì—¬ìžˆëŠ” ì´ë¯¸ì§€ëŠ” ë°°ê²½ì´ íˆ¬ëª…í•©ë‹ˆë‹¤.   \n",
    "    - ë”°ë¼ì„œ ë°°ê²½ ë¶€ë¶„ì€ BRGAì˜ Aê°’ì´ 0ìž…ë‹ˆë‹¤. \n",
    "    - ë°˜ë©´ ë°°ê²½ì´ ì•„ë‹Œ ì „ê²½ ë¶€ë¶„ì€ Aê°€ 0ì´ ì•„ë‹™ë‹ˆë‹¤.   \n",
    "    - ë”°ë¼ì„œ Aê°€ 1 ì´ìƒì´ë©´ 255, 1 ë¯¸ë§Œì´ë©´ 0ìœ¼ë¡œ ë°”ê¾¸ì–´ì£¼ë©´ ë°°ê²½ì€ ê²€ì€ìƒ‰, ì „ê²½ì€ í°ìƒ‰ì´ ë©ë‹ˆë‹¤.  \n",
    "\n",
    "    â— mask_inv = cv2.bitwise_not(mask)ì´ë¯€ë¡œ mask_invëŠ” maskì˜ ë°˜ëŒ€ìž…ë‹ˆë‹¤. \n",
    "    - ì¦‰, ë°°ê²½ì€ í°ìƒ‰, ì „ê²½ì€ ê²€ì€ìƒ‰ìž…ë‹ˆë‹¤.   \n",
    "    - ì´ ë‘ maskë¥¼ í™œìš©í•˜ì—¬ íŒŒë¦¬ ì´ë¯¸ì§€ì™€ OpenCV ì´ë¯¸ì§€ë¥¼ í•©ì„±í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Chroma key Masking and Blending  \n",
    "\n",
    "The color-based masking method is called chroma key.  \n",
    "For example, an actor shoots a green background and then later composites the green background with another background.   \n",
    "\n",
    "ìƒ‰ìƒì„ ì´ìš©í•œ ë§ˆìŠ¤í‚¹ ë°©ì‹ì„ **í¬ë¡œë§ˆí‚¤(chroma key)**ë¼ê³  í•©ë‹ˆë‹¤.  \n",
    "ì˜ˆë¥¼ ë“¤ì–´, ì´ˆë¡ìƒ‰ ë°°ê²½ì„ ë‘ê³  ë°°ìš°ê°€ ì´¬ì˜í•œ ë’¤ ë‚˜ì¤‘ì— ì´ˆë¡ìƒ‰ ë°°ê²½ì€ ë‹¤ë¥¸ ë°°ê²½ê³¼ í•©ì„±í•˜ëŠ” ë°©ì‹ìž…ë‹ˆë‹¤.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromakey.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/man_chromakey.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/street.jpg')\n",
    "\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "axs[0].imshow(img1_rgb), axs[0].axis('off'), axs[0].set_title('img1_rgb')\n",
    "axs[1].imshow(img2_rgb), axs[1].axis('off'), axs[1].set_title('img2_rgb')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height1, width1 = img1.shape[:2]\n",
    "height2, width2 = img2.shape[:2]\n",
    "x = (width2 - width1)//2\n",
    "y = height2 - height1\n",
    "w = x + width1\n",
    "h = y + height1\n",
    "\n",
    "chromakey = img1[:10, :10, :] # chromakey ROI with 10 pxls\n",
    "offset = 20\n",
    "\n",
    "hsv_chroma = cv2.cvtColor(chromakey, cv2.COLOR_BGR2HSV) # change to HSV\n",
    "hsv_img = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#chroma_h = hsv_chroma[0]\n",
    "chroma_h = hsv_chroma[:,:,0]\n",
    "lower = np.array([chroma_h.min()-offset, 100, 100])\n",
    "upper = np.array([chroma_h.max()+offset, 255, 255])\n",
    "\n",
    "mask = cv2.inRange(hsv_img, lower, upper)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "roi = img2[y:h, x:w]\n",
    "fg = cv2.bitwise_and(img1, img1, mask=mask_inv)\n",
    "bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "img2[y:h, x:w] = fg + bg\n",
    "\n",
    "cv2.imshow('chromakey', img1)\n",
    "cv2.imshow('added', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
    "axs[0].imshow(img1_rgb), axs[0].axis('off'), axs[0].set_title('chromakey')\n",
    "axs[1].imshow(img2_rgb), axs[1].axis('off'), axs[1].set_title('added')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ **cv2.seamlessClone()**  \n",
    "\n",
    "Image synthesis requires blending and masking as you see the above.   \n",
    "However, choosing alpha values for blending, coordinates for masking, and color selection takes a lot of time.  \n",
    "\n",
    "In OpenCV, there is a function called **cv2.seamlessClone()**, which functions to synthesize the characteristics of two images by itself.\n",
    "-  There is no need to select alpha values for blending, coordinates for masking, and color selection\n",
    "\n",
    "There is a function called cv2.seamlessClone()**, which functions to combine the characteristics of two images on its own.\n",
    "\n",
    "    ì´ë¯¸ì§€ í•©ì„±ì—ëŠ” ë¸”ë Œë”©ê³¼ ë§ˆìŠ¤í‚¹ì´ í•„ìš”í•©ë‹ˆë‹¤.   \n",
    "    í•˜ì§€ë§Œ, ë¸”ë Œë”©ì„ ìœ„í•œ ì•ŒíŒŒ ê°’ ì„ íƒê³¼ ë§ˆìŠ¤í‚¹ì„ ìœ„í•œ ì¢Œí‘œ, ìƒ‰ìƒ ì„ íƒì—ëŠ” ë§Žì€ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  \n",
    "    **cv2.seamlessClone()**ì´ë¼ëŠ” í•¨ìˆ˜ê°€ ìžˆëŠ”ë° ì´ëŠ” ë‘ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì‚´ë ¤ ì•Œì•„ì„œ í•©ì„±í•˜ëŠ” ê¸°ëŠ¥ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "~ Syntax:\n",
    "- **dst = cv2.seamlessClone(src, dst, mask, coords, flags, output)**\n",
    "\n",
    "~ Parameters:  \n",
    "    \n",
    ">- src: input img, foreground\n",
    ">- dst: out img, background\n",
    ">- mask: mask, The area you want to synthesize in src is 255, and the rest is 0\n",
    ">- coords: The coordinates of the dst where src wants to be placed. (center)\n",
    ">- flags: Synthesis method\n",
    ">>- cv2.NORMAL_CLONE : Preserve the input source  \n",
    ">>- cv2.MIXED_CLONE : Mix inputs and targets       \n",
    ">- output(optional): result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seamlessclone.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    " \n",
    "img1 = cv2.imread(\"./images/practice_img/drawing.jpg\")\n",
    "img2= cv2.imread(\"./images/practice_img/my_hand.jpg\")\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "axs[0].imshow(img1_rgb), axs[0].axis('off'), axs[0].set_title('img1_rgb')\n",
    "axs[1].imshow(img2_rgb), axs[1].axis('off'), axs[1].set_title('img2_rgb')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.full_like(img1, 255)\n",
    " \n",
    "height, width = img2.shape[:2] \n",
    "center = (width//2, height//2) # img center\n",
    "\n",
    "normal = cv2.seamlessClone(img1, img2, mask, center, cv2.NORMAL_CLONE) # seamlessClone\n",
    "mixed = cv2.seamlessClone(img1, img2, mask, center, cv2.MIXED_CLONE)\n",
    "\n",
    "cv2.imshow('normal', normal)\n",
    "cv2.imshow('mixed', mixed)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "normal_rgb = cv2.cvtColor(normal, cv2.COLOR_BGR2RGB)\n",
    "mixed_rgb = cv2.cvtColor(mixed, cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,10))\n",
    "axs[0].imshow(normal_rgb), axs[0].axis('off'), axs[0].set_title('cv2.NORMAL_CLONE')\n",
    "axs[1].imshow(mixed_rgb), axs[1].axis('off'), axs[1].set_title('cv2.MIXED_CLONE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Find the difference between two images  \n",
    "\n",
    "Subtracting the pixel values of the two images gives a negative number, so you need to take the absolute value.  \n",
    "\n",
    "~ Syntax:  \n",
    "    \n",
    "* **diff = cv2.absdiff(img1, img2)**  \n",
    "\n",
    "~ Parameters: \n",
    "    \n",
    "- img1, img2: imgs\n",
    "- diff: absolute value\n",
    "\n",
    "~ Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_absolute.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('./images/practice_img/robot_arm1.jpg')\n",
    "img2 = cv2.imread('./images/practice_img/robot_arm2.jpg')\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "diff = cv2.absdiff(img1_gray, img2_gray) # find differences of imgs\n",
    "\n",
    "_, diff = cv2.threshold(diff, 1, 255, cv2.THRESH_BINARY) # threshold and (inc differences)\n",
    "diff_red = cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)  # convert to color\n",
    "diff_red[:,:,2] = 0\n",
    "\n",
    "spot = cv2.bitwise_xor(img2, diff_red) # marking on spot\n",
    "\n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.imshow('diff', diff)\n",
    "cv2.imshow('spot', spot)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "spot_rgb = cv2.cvtColor(spot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
    "axs[0, 0].imshow(img1),axs[0, 0].axis('off'),axs[0, 0].set_title('Original img1')\n",
    "axs[0, 1].imshow(img2),axs[0, 1].axis('off'),axs[0, 1].set_title('Original img2')\n",
    "axs[1, 0].imshow(diff,cmap='gray'), axs[1, 0].axis('off'), axs[1, 0].set_title('Differences')\n",
    "axs[1, 1].imshow(spot_rgb), axs[1, 1].axis('off'), axs[1, 1].set_title('Different Spot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Reverse Image  \n",
    "\n",
    "Reverse Image is used to convert a video or image to an inverted color.  \n",
    "Each pixel is subjected to a bitwise operation, among which the NOT operation is applied.  \n",
    "The NOT operation is an operation that reverses the value of each digit.  \n",
    ">- If you apply the NOT operation to a pixel with a value of 153, it will be changed to a value of 102.\n",
    ">>- 153 has a value of 0b10011001, and 102 has a value of 0b01100110.\n",
    ">- That is, you change the pixel value of the decimal digit to the value of the binary number, and then reverse the value of each digit.\n",
    ">- 1 becomes 0, 0 changes to 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "src1 = cv2.imread(\"./images/practice_img/motorcycle.jpg\", cv2.IMREAD_COLOR) # pencil_small.jpg motorcycle.jpg butterfly.webp\n",
    "# src2 = cv2.imread(\"./images/practice_img/pistol.png\", cv2.IMREAD_COLOR) \n",
    "\n",
    "img_not = cv2.bitwise_not(src1)\n",
    "# img_and = cv2.bitwise_and(src1,src2)\n",
    "# img_or = cv2.bitwise_or(src1,src2)\n",
    "# img_xor = cv2.bitwise_xor(src1,src2)\n",
    "\n",
    "figure(figsize=(15, 10), dpi=100)\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv2.cvtColor(src1, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('off')\n",
    "plt.subplot(122),plt.imshow(cv2.cvtColor(img_not, cv2.COLOR_BGR2RGB)),plt.title('img_not'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV-py36",
   "language": "python",
   "name": "cv_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
