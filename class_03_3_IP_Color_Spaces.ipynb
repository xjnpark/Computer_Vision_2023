{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ğŸ‘‰ class_03_3 IP Â» _Changing Colorspaces - BGR, RGB, HSV, YUV_ </center>\n",
    "\n",
    "### Â» English (all) and Korean (some) for better understandings\n",
    "\n",
    "In this class, you will learn how to convert images from one color-space to another, like BGR-> Gray, BGR -> HSV etc.\n",
    "In addition to that, we will create an application which extracts a colored object in a image\n",
    "You will learn following functions : cv2.cvtColor(), cv2.inRange() etc.\n",
    "\n",
    "## Changing Colorspaces     \n",
    "\n",
    "There are more than 150 color-space conversion methods available in OpenCV.   \n",
    "But we will look into some of which are most widely used ones, BGR -> Gray and BGR -> HSV, and some more.\n",
    "\n",
    "For color conversion, we use the function **cv2.cvtColor(input_image, flag)** where flag determines the type of conversion.  \n",
    "- For BGR -> Gray conversion we use the flags cv2.COLOR_BGR2GRAY.   \n",
    "- Similarly for BGR -> HSV, we use the flag cv2.COLOR_BGR2HSV.   \n",
    "To get other flags, just run following commands in your Python terminal :  \n",
    "    \n",
    "ğŸ‘‰â¡ï¸[Color Space Conversions](https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#gga4e0972be5de079fed4e3a10e24ef5ef0a353a4b8db9040165db4dacb5bcefb6ea)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print(flags) # more than 150 color-space conversion methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ BGR, BGRA\n",
    "\n",
    "â— There is a method of expressing colors in the RGB (Red, Green, Blue) method.\n",
    "- It is a method of mixing three colors of light, red, green, and blue to create the desired color.\n",
    "- Each color is displayed as a value between 0~255, and the larger the value, the brighter the light of that color.  \n",
    "\n",
    ">â— ìƒ‰ìƒì„ í‘œí˜„í•˜ëŠ” ë°©ë²•ìœ¼ë¡œëŠ” RGB(Red, Green, Blue) ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤.   \n",
    ">- ë¹¨ê°•, ì´ˆë¡, íŒŒë‘ ì„¸ ê°€ì§€ ìƒ‰ì˜ ë¹›ì„ ì„ì–´ì„œ ì›í•˜ëŠ” ìƒ‰ì„ ë§Œë“œëŠ” ë°©ì‹ì…ë‹ˆë‹¤.   \n",
    ">- ê° ìƒ‰ìƒì€ 0~255 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‘œì‹œí•˜ê³  ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ í•´ë‹¹ ìƒ‰ìƒì˜ ë¹›ì´ ë°ì•„ì§€ëŠ” ì›ë¦¬ì…ë‹ˆë‹¤. \n",
    ">\n",
    ">- RGB = (255, 255, 255) : white, \n",
    ">- RGB = (0, 0, 0) : black. \n",
    ">\n",
    ">â— However, OpenCV expresses it in the opposite order: BGR.  \n",
    ">- RGB = (255, 0, 0) : red\n",
    ">- BGR = (255, 0, 0) : blue, red = (0, 0, 255).  \n",
    "\n",
    "â— RGBA is a color notation in which A (alpha) is added to RGB. \n",
    "- A means the transparency of the background. \n",
    "- A can also have a value of 0~255, but only 0 and 255 are often used to express the transparency of the background. \n",
    "- A value of 255 is white, 0 is black. \n",
    "\n",
    ">â— RGBAëŠ” RGBì— A(ì•ŒíŒŒ, alpha)ê°€ ì¶”ê°€ëœ ìƒ‰ìƒ í‘œê¸°ë²•ì…ë‹ˆë‹¤. \n",
    ">- AëŠ” ë°°ê²½ì˜ íˆ¬ëª…ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. \n",
    ">- A ì—­ì‹œ 0~255ì˜ ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ë°°ê²½ì˜ íˆ¬ëª…ë„ë¥¼ í‘œí˜„í•˜ê¸° ìœ„í•´ 0ê³¼ 255ë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. \n",
    ">- Aê°’ì´ 255ë©´ í°ìƒ‰, 0ì´ë©´ ê²€ì€ìƒ‰ì…ë‹ˆë‹¤. \n",
    "\n",
    "~ Examples:\n",
    "- cv2.imread() function as the second parameter- a IMREAD_COLOR(default), the image will be read using the BGR method.    \n",
    ">- cv2.imread() í•¨ìˆ˜ì— ë‘ ë²ˆì§¸ íŒŒë¼ë¯¸í„°ë¡œ cv2.IMREAD_COLORë¥¼ ë„£ì–´ì£¼ë©´ BGR ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì½ìŠµë‹ˆë‹¤.  \n",
    "- If the second parameter is IMREAD_UNCHANGED and the image has an alpha channel, it is read in the BGRA way.\n",
    ">- cv2.IMREAD_UNCHANGEDì¸ ê²½ìš° ì´ë¯¸ì§€ê°€ ì•ŒíŒŒ ì±„ë„ì„ ê°€ì§€ê³  ìˆëŠ” ê²½ìš° BGRA ë°©ì‹ìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR, BGRA, Ahlpha ì±„ë„ (rgba.py)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./images/opencv-logo.png')   # default = cv2.IMREAD_COLOR\n",
    "bgr = cv2.imread('./images/opencv-logo.png', cv2.IMREAD_COLOR)   \n",
    "bgra = cv2.imread('./images/opencv-logo.png', cv2.IMREAD_UNCHANGED) \n",
    "print(\"default\", img.shape, \"color\", bgr.shape, \"unchanged\", bgra.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('bgr', bgr)\n",
    "cv2.imshow('bgra', bgra)\n",
    "cv2.imshow('alpha', bgra[:,:,3])  # alpha channel\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "# rgba = cv2.cvtColor(bgra, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15,10))\n",
    "axs[0, 0].imshow(bgr), axs[0, 0].axis('off'), axs[0, 0].set_title('bgr')\n",
    "axs[0, 1].imshow(bgra), axs[0, 1].axis('off'), axs[0, 1].set_title('bgra')\n",
    "axs[0, 2].imshow(bgra[:,:,3],cmap='gray'), axs[0, 2].axis('off'), axs[0, 2].set_title('alpha only Img')\n",
    "axs[1, 0].imshow(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)), axs[1, 0].axis('off'), axs[1, 0].set_title('bgr2rgb')\n",
    "axs[1, 1].imshow(cv2.cvtColor(bgra, cv2.COLOR_BGRA2RGBA)), axs[1, 1].axis('off'), axs[1, 1].set_title('bgra2rgba')\n",
    "axs[1, 2].imshow(bgra[:,:,3],cmap='gray'), axs[1, 2].axis('off'), axs[1, 2].set_title('alpha only Img')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is no difference between an image that is delivered to the IMREAD_COLOR and an image that does not pass any parameters. \n",
    "- Since the background is black, you can't even see the black text OpenCV. \n",
    "- Also, both the first and second images have the same shape of (794, 600, 3).   \n",
    "- On the other hand, the third image has one more alpha channel, so the shape is (794, 600, 4). \n",
    ">- In the third image, you can see that the alpha value in the foreground is 255 (white)   \n",
    ">- and the alpha value in the background is 0 (black). \n",
    ">- Unlike the first and second images, the third image only shows the alpha channel, so you can easily separate the foreground from the background. \n",
    ">- For this reason, the alpha channel is also called the mask channel.\n",
    "\n",
    "- íŒŒë¼ë¯¸í„°ë¥¼ cv2.IMREAD_COLORë¡œ ì „ë‹¬í•œ ê²ƒê³¼ ì•„ë¬´ íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì˜ ì°¨ì´ëŠ” ì—†ìŠµë‹ˆë‹¤. \n",
    "- ë°°ê²½ì´ ê²€ì€ìƒ‰ì´ë‹¤ ë³´ë‹ˆ OpenCVë¼ëŠ” ê²€ì€ìƒ‰ ê¸€ì”¨ë„ ì•ˆ ë³´ì…ë‹ˆë‹¤. \n",
    "- ë˜í•œ, ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ ëª¨ë‘ shapeê°€ (794, 600, 3)ì…ë‹ˆë‹¤.   \n",
    "- ë°˜ë©´ ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ì•ŒíŒŒ ì±„ë„ì´ í•˜ë‚˜ ë” ìˆì–´ shapeê°€ (794, 600, 4)ì…ë‹ˆë‹¤. \n",
    ">- ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ì—ì„œ ì „ê²½ì˜ ì•ŒíŒŒ ê°’ì€ 255 (í°ìƒ‰), ë°°ê²½ì˜ ì•ŒíŒŒ ê°’ì€ 0 (ê²€ì€ìƒ‰)ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    ">- ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ì™€ ë‹¬ë¦¬ ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ì•ŒíŒŒ ì±„ë„ë§Œ í‘œì‹œí–ˆìœ¼ë¯€ë¡œ ì „ê²½ê³¼ ë°°ê²½ì„ ì‰½ê²Œ ë¶„ë¦¬í•´ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    ">- ì´ëŸ° ì´ìœ ë¡œ ì•ŒíŒŒ ì±„ë„ì€ ë§ˆìŠ¤í¬ ì±„ë„(mask channel)ì´ë¼ê³ ë„ ë¶€ë¦…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ BGR to Grayscale Img  \n",
    "\n",
    "Converting color images to grayscale images is essential to speed up the computation by reducing the amount of image computation.   \n",
    "- The function that reads in grayscale from the beginning is cv2.imread(img, cv2. IMREAD_GRAYSCALE).   \n",
    ">- cv2.imread() function as the second parameter of cv2. You can do this by passing the IMREAD_GRAYSCALE.   \n",
    "However, there are times when it is necessary to read it as a BGR color image at first and then convert it to grayscale.   \n",
    "This can be implemented with the cv2.cvtcolor() function.   \n",
    "\n",
    "ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ íšŒìƒ‰ì¡° ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì€ ì´ë¯¸ì§€ ì—°ì‚°ì˜ ì–‘ì„ ì¤„ì—¬ì„œ ì†ë„ë¥¼ ë†’ì´ëŠ” ë° ê¼­ í•„ìš”í•©ë‹ˆë‹¤.   \n",
    "- ì²˜ìŒë¶€í„° íšŒìƒ‰ì¡°ë¡œ ì½ì–´ ë“¤ì´ëŠ” í•¨ìˆ˜ëŠ” cv2.imread(img, cv2.IMREAD_GRAYSCALE)ì…ë‹ˆë‹¤.   \n",
    "- cv2.imread() í•¨ìˆ˜ì˜ ë‘ ë²ˆì§¸ íŒŒë¼ë¯¸í„°ë¡œ cv2.IMREAD_GRAYSCALEì„ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤.   \n",
    "ê·¸ëŸ¬ë‚˜ ì²˜ìŒì—ëŠ” BGR ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ì½ì–´ ë“¤ì´ê³  ê·¸ ì´í›„ì— íšŒìƒ‰ì¡°ë¡œ ë³€í™˜í•´ì•¼ í•  ë•Œë„ ìˆìŠµë‹ˆë‹¤.   \n",
    "ì´ëŠ” cv2.cvtcolor() í•¨ìˆ˜ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "\n",
    "There are two ways to convert a color image to a grayscale image.\n",
    "- The first method is to implement it directly using the average value,   \n",
    "- The second method is to use the cv2.cvtcolor() function provided by OpenCV.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgr2gray\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./images/lady.jpg')\n",
    "\n",
    "img2 = img.astype(np.uint16)                \n",
    "b,g,r = cv2.split(img2)                     \n",
    "#b,g,r = img2[:,:,0], img2[:,:,1], img2[:,:,2]\n",
    "gray1 = ((b + g + r)/3).astype(np.uint8)    \n",
    "\n",
    "gray2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('Avg_gray', gray1)\n",
    "cv2.imshow('BGR2GRAY', gray2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Before getting the average value, You need to change the dtype to unit16 (0 ~ 65,535). \n",
    "- This is because the sum of the values of the three channels can yield a value greater than 255.   \n",
    "- After averaging it, change it back to unit8 (0 ~ 255). \n",
    "- The cv2.split(img2) function separates each BGR channel and returns it as a tuple. This is the same as numpy slicing. \n",
    "- So the two codes below are the same code.\n",
    ">- b, g, r = cv2.split(img2)  \n",
    ">- b, g, r = img2[:, :, 0], img2[:, :, 1], img2[:, :, 2]  \n",
    "\n",
    "    1. í‰ê· ê°’ì„ êµ¬í•˜ê¸° ì „ì— dtypeì„ unit16ìœ¼ë¡œ ë°”ê¿”ì£¼ì—ˆìŠµë‹ˆë‹¤. \n",
    "    - 3 ì±„ë„ì˜ ê°’ì„ í•©í•˜ë©´ 255ë³´ë‹¤ í° ê°’ì´ ë‚˜ì˜¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.   \n",
    "    - í‰ê· ì„ êµ¬í•œ ë’¤ì—ëŠ” ë‹¤ì‹œ unit8ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤. \n",
    "    - cv2.split(img2) í•¨ìˆ˜ëŠ” BGR ì±„ë„ë³„ë¡œ ë¶„ë¦¬í•´ì„œ íŠœí”Œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ëŠ” numpy ìŠ¬ë¼ì´ì‹±ê³¼ ë™ì¼í•©ë‹ˆë‹¤. \n",
    "    - ë”°ë¼ì„œ ì•„ë˜ì˜ ë‘ ì½”ë“œëŠ” ë™ì¼í•œ ì½”ë“œì…ë‹ˆë‹¤.\n",
    "\n",
    "2. Use cv2.cvtcolor(img, cv2.COLOR_BRG2GRAY) \n",
    "\n",
    "\n",
    "There are a total of 274 flag parameters, but the most frequently used ones are:\n",
    "\n",
    "- cv2.COLOR_BGR2GRAY: BGR to GRAY img\n",
    "- cv2.COLOR_GRAY2BGR: GRAY to BGR \n",
    "- cv2.COLOR_BGR2RGB: BGR to RGB \n",
    "- cv2.COLOR_BGR2HSV: BGR to HSV \n",
    "- cv2.COLOR_HSV2BGR: HSV to BGR \n",
    "- cv2.COLOR_BGR2YUV: BGR to YUV \n",
    "- cv2.COLOR_YUV2BGR: YUB to BGR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print(flags) # more than 270 color-space conversion methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ HSV(Hue, Saturation, Value)    \n",
    "https://076923.github.io/posts/Python-opencv-15/  \n",
    "https://en.wikipedia.org/wiki/HSL_and_HSV  \n",
    "    \n",
    "â— HSL(for hue, saturation, lightness) and HSV (for hue, saturation, value; also known as HSB, for hue, saturation, brightness) are alternative representations of the RGB color model, designed in the 1970s by computer graphics researchers.    \n",
    "\n",
    "â— HSL, HSV, HSI(intensity), or related models are often used in computer vision and image analysis for feature detection or image segmentation.   \n",
    "\n",
    "â— The applications of such tools include object detection,   \n",
    ">- for instance in robot vision; object recognition,   \n",
    ">- for instance of faces, text, or license plates; content-based image retrieval;   \n",
    ">- and analysis of medical images.  \n",
    "\n",
    "â— Why convert RGB to HSV?  \n",
    "- In order to detect color information in an RGB image, all three properties of R, G, and B must be referenced.\n",
    "- However, in HSV images, H (Hue) has pure color information with a certain range, so colors can be classified more easily than RGB images.\n",
    "\n",
    "â— The HSV method is a color image representation method with three channels, just like RGB.  \n",
    "HSV (Hue, Saturation, Value) is a color space that is easy to express colors.  \n",
    "Assuming that color is detected in an image, it is very difficult and complex to distinguish colors in the area perceived by humans with BGR or RGB patterns.  \n",
    "However, if you take advantage of the HSV color space, you can easily and quickly detect and isolate specific colors.  \n",
    "\n",
    "    â€¢ HSV ë°©ì‹ì€ RGBì™€ ë§ˆì°¬ê°€ì§€ë¡œ 3ê°œì˜ ì±„ë„ì„ ê°–ëŠ” ìƒ‰ìƒ ì´ë¯¸ì§€ í‘œí˜„ë²•ì…ë‹ˆë‹¤.    \n",
    "      HSV(Hue, Saturation, Value) ê³µê°„ì€ ìƒ‰ìƒì„ í‘œí˜„í•˜ê¸°ì— ê°„í¸í•œ ìƒ‰ìƒ ê³µê°„ì…ë‹ˆë‹¤.     \n",
    "      ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒì„ ê²€ì¶œí•œë‹¤ê³  ê°€ì •í•  ë•Œ BGRì´ë‚˜ RGB íŒ¨í„´ìœ¼ë¡œëŠ” ì¸ê°„ì´ ì¸ì§€í•˜ëŠ” ì˜ì—­ì˜ ìƒ‰ìƒì„ êµ¬ë³„í•˜ê¸°ì—ëŠ” ë§¤ìš° ì–´ë µê³  ë³µì¡í•©ë‹ˆë‹¤.\n",
    "      í•˜ì§€ë§Œ HSV ìƒ‰ìƒ ê³µê°„ì„ í™œìš©í•œë‹¤ë©´ ê°„í¸í•˜ê³  ë¹ ë¥´ê²Œ íŠ¹ì • ìƒ‰ìƒì„ ê²€ì¶œí•˜ê³  ë¶„ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    \n",
    "\n",
    "<img src='./images/hsv_hsl.png'  width=800 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H(Hue, ìƒ‰ì¡°), S(Saturation, ì±„ë„), V(Value, ëª…ë„)\n",
    "\n",
    "H, S, and V are as follows:  \n",
    "* Hue corresponds to the color components (base pigment), hence just by selecting a range of Hue you can select any color.(0 ~ 360)    \n",
    ">- opencv : 0 ~ 180     \n",
    "* Saturation is the amount of color (depth of the pigment) - dominance of Hue - (0 ~ 100%)   \n",
    ">- opencv : 0 ~ 255\n",
    "* Value is basically the brightness of the color (0 ~ 100%) \n",
    ">- opencv : 0 ~ 255\n",
    "\n",
    "* **ìƒ‰ì¡°(Hue)**ì€ ë¹¨ê°„ìƒ‰, ë…¸ë€ìƒ‰, íŒŒë€ìƒ‰ ë“±ìœ¼ë¡œ ì¸ì‹ë˜ëŠ” ìƒ‰ìƒ ì¤‘ í•˜ë‚˜ ë˜ëŠ” ë‘˜ì˜ ì¡°í•©ê³¼ ìœ ì‚¬í•œ ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ì‹œê°ì  ê°ê°ì˜ ì†ì„±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "0Â°ì—ì„œ 360Â°ì˜ ë²”ìœ„ë¡œ í‘œí˜„ë˜ë©°, íŒŒë€ìƒ‰ì€ 220Â°ì—ì„œ 260Â° ì‚¬ì´ì— ìˆìŠµë‹ˆë‹¤. \n",
    ">- OpenCVì—ì„œëŠ” 0 ~ 180ì˜ ë²”ìœ„ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.    \n",
    "* **ì±„ë„(Saturation)**ëŠ” ì´ë¯¸ì§€ì˜ ìƒ‰ìƒ ê¹Šì´ë¡œ, ìƒ‰ìƒì´ ì–¼ë§ˆë‚˜ ì„ ëª…í•œ(ìˆœìˆ˜í•œ) ìƒ‰ì¸ì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ì„ì§€ ì•Šì•„ ë§‘ê³  ê¹¨ë—í•˜ë©° ì›ìƒ‰ì— ê°€ê¹Œìš´ ê²ƒì„ ì±„ë„ê°€ ë†’ë‹¤ê³  í‘œí˜„í•©ë‹ˆë‹¤.\n",
    "0%ì—ì„œ 100%ì˜ ë¹„ìœ¨ë¡œ í‘œí˜„ë˜ë©°, 0%ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë¬´ì±„ìƒ‰, 100%ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°€ì¥ ì„ ëª…í•œ(ìˆœìˆ˜í•œ)ìƒ‰ì´ ë©ë‹ˆë‹¤. \n",
    ">- OpenCVì—ì„œëŠ” 0 ~ 255ì˜ ë²”ìœ„ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.  \n",
    "\n",
    "* **ëª…ë„(Value)**ëŠ” ìƒ‰ì˜ ë°ê³  ì–´ë‘ìš´ ì •ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ëª…ë„ê°€ ë†’ì„ìˆ˜ë¡ ìƒ‰ìƒì´ ë°ì•„ì§€ë©°, ëª…ë„ê°€ ë‚®ì„ìˆ˜ë¡ ìƒ‰ìƒì´ ì–´ë‘ì›Œì§‘ë‹ˆë‹¤.\n",
    "0%ì—ì„œ 100%ì˜ ë¹„ìœ¨ë¡œ í‘œí˜„ë˜ë©°, 0%ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê²€ì€ìƒ‰, 100%ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°€ì¥ ë§‘ì€ìƒ‰ì´ ë©ë‹ˆë‹¤. \n",
    ">- OpenCVì—ì„œëŠ” 0 ~ 255ì˜ ë²”ìœ„ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ğŸ˜ŠTip : Since the range of 0 ~ 360 is outside the range of 1 Byte (uint8), it is expressed as a range of 0 ~ 179, which is half the value, to reduce unnecessary memory usage.  \n",
    "    \n",
    "    0 ~ 360ì˜ ë²”ìœ„ëŠ” 1 Byte(uint8)ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ê²Œ ë˜ë¯€ë¡œ ë¶ˆí•„ìš”í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì´ê¸° ìœ„í•´, ì ˆë°˜ì˜ ê°’ì¸ 0 ~ 179ì˜ ë²”ìœ„ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.  \n",
    "\n",
    "<img src = './images/hsv.png' align='left' width=300 height=400> <img src = './images/practice_img/hsv1.jpg' width=400 height=500>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgr2hsv\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "red_bgr = np.array([[[0,0,255]]], dtype=np.uint8)   # red\n",
    "green_bgr = np.array([[[0,255,0]]], dtype=np.uint8) \n",
    "blue_bgr = np.array([[[255,0,0]]], dtype=np.uint8) \n",
    "yellow_bgr = np.array([[[0,255,255]]], dtype=np.uint8) # yellow\n",
    "\n",
    "red_hsv = cv2.cvtColor(red_bgr, cv2.COLOR_BGR2HSV);    # HSV \n",
    "green_hsv = cv2.cvtColor(green_bgr, cv2.COLOR_BGR2HSV);\n",
    "blue_hsv = cv2.cvtColor(blue_bgr, cv2.COLOR_BGR2HSV);\n",
    "yellow_hsv = cv2.cvtColor(yellow_bgr, cv2.COLOR_BGR2HSV);\n",
    "\n",
    "print(\"HSV_red:\",red_hsv)\n",
    "print(\"HSV_green:\", green_hsv)\n",
    "print(\"HSV_blue\", blue_hsv)\n",
    "print(\"HSV_yellow\", yellow_hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If a red color with a BGR of (0, 0, 255) is expressed in HSV, it is (0, 255, 255).   \n",
    "- In order to find out the color, the RGB method needs to know the values of all three channels, but the HSV method is more convenient and effective because it only needs to know the H value.\n",
    "\n",
    "\n",
    "- BGRì´ (0, 0, 255)ì¸ ìƒ‰ì„ HSVë¡œ í‘œí˜„í•˜ë©´ (0, 255, 255)ì…ë‹ˆë‹¤.   \n",
    "- ìƒ‰ìƒì„ ì•Œì•„ë‚´ê¸° ìœ„í•´ì„œ RGB ë°©ì‹ì€ ì„¸ ê°€ì§€ ì±„ë„ì˜ ê°’ì„ ëª¨ë‘ ì•Œì•„ì•¼ í•˜ì§€ë§Œ, HSV ë°©ì‹ì€ ì˜¤ì§ Hê°’ í•˜ë‚˜ë§Œ ì•Œë©´ ë˜ë¯€ë¡œ ì¢€ ë” í¸ë¦¬í•˜ê³  íš¨ê³¼ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘‰ RGB to HSV conversion formula  \n",
    "https://www.rapidtables.com/convert/color/rgb-to-hsv.html  \n",
    "    \n",
    "The R,G,B values are divided by 255 to change the range from 0..255 to 0..1:  \n",
    "    \n",
    "$$ R' = R/255 $$   \n",
    "$$ G' = G/255 $$  \n",
    "$$ B' = B/255 $$  \n",
    "$$ Cmax = max(R', G', B')$$   \n",
    "$$ Cmin = min(R', G', B') $$  \n",
    "$$ Î” = Cmax - Cmin $$\n",
    "\n",
    "Hue calculation:\n",
    "<img src='./images/hue-calc.png'  width=400 height=400>\n",
    "Saturation calculation:\n",
    "<img src='./images/sat-calc.png'  width=200 height=200>\n",
    "\n",
    "Value calculation:\n",
    "$$ V = Cmax $$\n",
    "<img src='./images/hue-val-calc.png'  width=300 height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ˜Š RGB to HSV color table  \n",
    "\n",
    "<img src='./images/hsv_table.png'  width=400 height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"./images/practice_img/hsv1.webp\", cv2.IMREAD_COLOR)\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv) # The separate channels are single channels (only in black and white colors\n",
    "\n",
    "cv2.imshow(\"Hue\", h)\n",
    "cv2.imshow(\"Saturation\", s)\n",
    "cv2.imshow(\"Value\", v)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_rgb = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15,5))\n",
    "axs[0, 0].imshow(src_rgb),axs[0, 0].axis('off'),axs[0, 0].set_title('Original')\n",
    "axs[0, 1].imshow(h,cmap='gray'),axs[0, 1].axis('off'),axs[0, 1].set_title('Hue')\n",
    "axs[1, 0].imshow(s,cmap='gray'), axs[1, 0].axis('off'), axs[1, 0].set_title('Saturation')\n",
    "axs[1, 1].imshow(v,cmap='gray'), axs[1, 1].axis('off'), axs[1, 1].set_title('Value')\n",
    "\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='x-label', ylabel='y-label')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hueì˜ ë²”ìœ„ë¥¼ ì¡°ì •í•˜ì—¬ íŠ¹ì • ìƒ‰ìƒì˜ ë²”ìœ„ë§Œ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "- ë°°ì—´ ìš”ì†Œì˜ ë²”ìœ„ ì„¤ì • í•¨ìˆ˜(cv2.inRange)ë¡œ ì…ë ¥ëœ ë°°ì—´ì˜ íŠ¹ì • ë²”ìœ„ ì˜ì—­ë§Œ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* **dst = cv2.inRange(src, lowerb, upperb)**ëŠ” ì…ë ¥ ì´ë¯¸ì§€(src)ì˜ ë‚®ì€ ë²”ìœ„(lowerb)ì—ì„œ ë†’ì€ ë²”ìœ„(upperb) ì‚¬ì´ì˜ ìš”ì†Œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.  \n",
    "\n",
    "- ì£¼í™©ìƒ‰ì€ ì•½ 8 ~ 20 ë²”ìœ„ë¥¼ ê°–ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´í›„, í•´ë‹¹ ì¶”ì¶œí•œ ì˜ì—­ì„ ë§ˆìŠ¤í¬ë¡œ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ìœ„ì— ë§ì”Œì›Œ í•´ë‹¹ ë¶€ë¶„ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.  \n",
    "- ë¹„íŠ¸ ì—°ì‚° AND(cv2.bitwise_and)ë¡œ ê°„ë‹¨í•˜ê²Œ ë§ˆìŠ¤í¬ë¥¼ ë§ì”Œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* **dst = cv2.bitwise_and(src1, src2, mask)**ëŠ” ì…ë ¥ ì´ë¯¸ì§€1(src1)ê³¼ ì…ë ¥ ì´ë¯¸ì§€2(src2)ì˜ í”½ì…€ì˜ ì´ì§„ê°’ì´ ë™ì¼í•œ ì˜ì—­ë§Œ AND ì—°ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.  \n",
    "\n",
    "ë§ˆìŠ¤í¬ ì˜ì—­ì´ ì¡´ì¬í•œë‹¤ë©´ ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ AND ì—°ì‚°ì„ ì§„í–‰í•©ë‹ˆë‹¤.  \n",
    "íŠ¹ì • ì˜ì—­(ë§ˆìŠ¤í¬)ì˜ AND ì—°ì‚°ì´ ì™„ë£Œëë‹¤ë©´ ë‹¤ì‹œ HSV ìƒ‰ìƒ ê³µê°„ì—ì„œ BGR ìƒ‰ìƒ ê³µê°„ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
    "\n",
    "~ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"./images/practice_img/hsv1.webp\", cv2.IMREAD_COLOR)\n",
    "\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "h = cv2.inRange(h, 8, 20) # orange color\n",
    "orange = cv2.bitwise_and(hsv, hsv, mask = h)\n",
    "orange = cv2.cvtColor(orange, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow(\"orange\", orange)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_rgb = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "orange_plt = cv2.cvtColor(orange, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "axs[0].imshow(src_rgb), axs[0].axis('off'), axs[0].set_title('Original')\n",
    "axs[1].imshow(orange_plt), axs[1].axis('off'), axs[1].set_title('Orange Color Only')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to another color extract : \n",
    "\n",
    "HSVì˜ ìƒ‰ìƒ \n",
    "\n",
    "<img src='./images/hsv_img.png'  width=1000 height=100>\n",
    "\n",
    "https://brunch.co.kr/@chulhochoiucj0/17\n",
    "    \n",
    "<img src='./images/hsv_img2.png'  width=1000 height=400>  \n",
    "\n",
    "* The x-axis represents Hue in [0,180),   \n",
    "* the y-axis1 represents Saturation in [0,255],   \n",
    "* the y-axis2 represents S = 255,   \n",
    "* while keep V = 255.  \n",
    "                                \n",
    "To find a color, usually just look up for the range of H and S, and set v in range(20, 255).  \n",
    "- To find the orange color, we look up for the map, and find the best range: H :[10, 25], S: [100, 255], and V: [20, 255].   \n",
    "- So the mask is cv2.inRange(hsv,(10, 100, 20), (25, 255, 255) )\n",
    "\n",
    "Then we use the found range to look for the orange color, this is the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the right colors and numbers?\n",
    "\n",
    "https://github.com/alkasm/colorfilters\n",
    "    \n",
    "ğŸ‘‰ COLOR RANGE  \n",
    "First value is the upper limit and second value is the lower limit of [h, s, v]:  \n",
    "    \n",
    "|color   |    Upper LMT   |  Lower LMT    \n",
    "|-------|---------------|-----------  \n",
    "|'black' |[180, 255, 30]| [0, 0, 0]  \n",
    "|'white'| [180, 18, 255] |[0, 0, 231]  \n",
    "|'red1' |[180, 255, 255]| [159, 50, 70]  \n",
    "|'red2' |[9, 255, 255]| [0, 50, 70]  \n",
    "|'green'| [89, 255, 255]| [36, 50, 70]  \n",
    "|'blue' |[128, 255, 255]| [90, 50, 70]  \n",
    "|'yellow'| [35, 255, 255]| [25, 50, 70]  \n",
    "|'purple'| [158, 255, 255]| [129, 50, 70]  \n",
    "|'orange'| [24, 255, 255]| [10, 50, 70]  \n",
    "|'gray'| [180, 18, 230]| [0, 0, 40]     \n",
    "\n",
    "~ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "img = cv2.imread(\"./images/practice_img/hsv1.webp\", cv2.IMREAD_COLOR)\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # BGR to HSV ë³€í™˜\n",
    "h, s, v = cv2.split(hsv)\n",
    "h_or = cv2.inRange(h, 8, 20) # orange color\n",
    "h_gr = cv2.inRange(h, 36, 70) # mask of green (36,0,0) ~ (70, 255,255)\n",
    "h_yl = cv2.inRange(h, 15, 36) # mask of yellow (15,0,0) ~ (36, 255, 255)\n",
    "# h_rd = cv2.inRange(h, 0, 9) # mask of red (0, 50, 70) ~ (9, 255, 255)\n",
    "h_rd = cv2.inRange(h, 159, 180) # mask of red (0, 50, 70) ~ (9, 255, 255)\n",
    "# hsv_rd= cv2.inRange(hsv,(0, 50, 70), (9, 255, 255) ) # 'red2': [[9, 255, 255], [0, 50, 70]\n",
    "# hsv_rd= cv2.inRange(hsv,(159, 50, 70), (180, 255, 255) ) # 'red1': [[180, 255, 255], [159, 50, 70]]\n",
    "\n",
    "orange = cv2.bitwise_and(hsv, hsv, mask = h_or)\n",
    "orange = cv2.cvtColor(orange, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "green = cv2.bitwise_and(hsv, hsv, mask = h_gr)\n",
    "green = cv2.cvtColor(green, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "yellow = cv2.bitwise_and(hsv, hsv, mask = h_yl)\n",
    "yellow = cv2.cvtColor(yellow, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "red = cv2.bitwise_and(hsv, hsv, mask = h_rd)\n",
    "# red = cv2.bitwise_and(hsv, hsv, mask = hsv_rd)\n",
    "red = cv2.cvtColor(red, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "or_yl = cv2.bitwise_or(h_or, h_yl) # mask and masked (orange and yellow)\n",
    "orange_yellow = cv2.bitwise_and(img,img, mask=or_yl)\n",
    "\n",
    "rd_or = cv2.bitwise_or(h_rd, h_or) # mask and masked (red and orange )\n",
    "red_orange = cv2.bitwise_and(img,img, mask=rd_or)\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"orange\", orange)\n",
    "cv2.imshow(\"green\", green)\n",
    "cv2.imshow(\"yellow\", yellow)\n",
    "cv2.imshow(\"orange_yellow\", orange_yellow)\n",
    "cv2.imshow(\"red\", red)\n",
    "cv2.imshow(\"red_orange\", red_orange)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15, 15), dpi=100)\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),plt.title('original'),plt.axis('off')\n",
    "plt.subplot(122),plt.imshow(img_hsv),plt.title('hsv'),plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "figure(figsize=(15, 15), dpi=100)\n",
    "\n",
    "plt.subplot(131),plt.imshow(cv2.cvtColor(orange, cv2.COLOR_BGR2RGB)),plt.title('orange'),plt.axis('off')\n",
    "plt.subplot(132),plt.imshow(cv2.cvtColor(green, cv2.COLOR_BGR2RGB)),plt.title('green'),plt.axis('off')\n",
    "plt.subplot(133),plt.imshow(cv2.cvtColor(yellow, cv2.COLOR_BGR2RGB)),plt.title('yellow'),plt.axis('off')\n",
    "plt.show()\n",
    "figure(figsize=(15, 15), dpi=100)\n",
    "\n",
    "plt.subplot(131),plt.imshow(cv2.cvtColor(orange_yellow, cv2.COLOR_BGR2RGB)),plt.title('orange_yellow'),plt.axis('off')\n",
    "plt.subplot(132),plt.imshow(cv2.cvtColor(red, cv2.COLOR_BGR2RGB)),plt.title('red'),plt.axis('off')\n",
    "plt.subplot(133),plt.imshow(cv2.cvtColor(red_orange, cv2.COLOR_BGR2RGB)),plt.title('red_orange'),plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ˜Š Here's a simple HSV color thresholder script to determine the lower/upper color ranges using trackbars for any image on the disk.   \n",
    "\n",
    "Simply change the image path in cv2.imread(). Example to isolate orange:\n",
    "\n",
    "enter image description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "image = cv2.imread(\"./images/practice_img/hsv1.webp\", cv2.IMREAD_COLOR)\n",
    "cv2.namedWindow('image') # Create a named Window for later use\n",
    "\n",
    "# Create trackbars for color change\n",
    "cv2.createTrackbar('HMin', 'image', 0, 179, nothing) # Hue is from 0-179 for Opencv\n",
    "cv2.createTrackbar('SMin', 'image', 0, 255, nothing) \n",
    "cv2.createTrackbar('VMin', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('HMax', 'image', 0, 179, nothing)\n",
    "cv2.createTrackbar('SMax', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('VMax', 'image', 0, 255, nothing)\n",
    "\n",
    "# Set default value for Max HSV trackbars\n",
    "cv2.setTrackbarPos('HMax', 'image', 179)\n",
    "cv2.setTrackbarPos('SMax', 'image', 255)\n",
    "cv2.setTrackbarPos('VMax', 'image', 255)\n",
    "\n",
    "# Initialize HSV min/max values\n",
    "hMin = sMin = vMin = hMax = sMax = vMax = 0\n",
    "phMin = psMin = pvMin = phMax = psMax = pvMax = 0\n",
    "\n",
    "while(1):\n",
    "    # Get current positions of all trackbars\n",
    "    hMin = cv2.getTrackbarPos('HMin', 'image')\n",
    "    sMin = cv2.getTrackbarPos('SMin', 'image')\n",
    "    vMin = cv2.getTrackbarPos('VMin', 'image')\n",
    "    hMax = cv2.getTrackbarPos('HMax', 'image')\n",
    "    sMax = cv2.getTrackbarPos('SMax', 'image')\n",
    "    vMax = cv2.getTrackbarPos('VMax', 'image')\n",
    "\n",
    "    # Set minimum and maximum HSV values to display\n",
    "    lower = np.array([hMin, sMin, vMin])\n",
    "    upper = np.array([hMax, sMax, vMax])\n",
    "\n",
    "    # Convert to HSV format and color threshold\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Print if there is a change in HSV value\n",
    "    if((phMin != hMin) | (psMin != sMin) | (pvMin != vMin) | (phMax != hMax) | (psMax != sMax) | (pvMax != vMax) ):\n",
    "        print(\"(hMin = %d , sMin = %d, vMin = %d), (hMax = %d , sMax = %d, vMax = %d)\" % (hMin , sMin , vMin, hMax, sMax , vMax))\n",
    "        phMin = hMin\n",
    "        psMin = sMin\n",
    "        pvMin = vMin\n",
    "        phMax = hMax\n",
    "        psMax = sMax\n",
    "        pvMax = vMax\n",
    "\n",
    "    # Display result image\n",
    "    cv2.imshow('image', result)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSV lower/upper color threshold ranges : \n",
    "- (hMin = 16 , sMin = 29, vMin = 0), (hMax = 167 , sMax = 255, vMax = 255)  \n",
    "\n",
    "Once you have determined your lower and upper HSV color ranges, you can segment your desired colors like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"./images/practice_img/hsv1.webp\", cv2.IMREAD_COLOR)\n",
    "\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "lower = np.array([16, 29, 0])\n",
    "upper = np.array([167, 255, 255])\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "cv2.imshow('result', result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(15, 15), dpi=120)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)),plt.title('hMin = 16 , sMin = 29, vMin = 0, hMax = 167 , sMax = 255, vMax = 255 ')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way to find HSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = np.uint8([[[255,0,0 ]]])\n",
    "green = np.uint8([[[0,255,0 ]]])\n",
    "red = np.uint8([[[0,0,255 ]]])\n",
    "hsv_blue = cv2.cvtColor(blue,cv2.COLOR_BGR2HSV)\n",
    "hsv_green = cv2.cvtColor(green,cv2.COLOR_BGR2HSV)\n",
    "hsv_red = cv2.cvtColor(red,cv2.COLOR_BGR2HSV)\n",
    "print(hsv_blue, hsv_green, hsv_red)\n",
    "# [[[ 60 255 255]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ addWeighted  \n",
    "\n",
    "â— When detecting color in an image or image, you can limit the part where the color is set by the range setting function (cv2.inRange) of the array element.    \n",
    "- For example, when trying to detect the red area, the red area is divided into two ranges:   \n",
    ">- about 0 ~ 5 and about 170 ~ 179.  \n",
    "- To solve this problem, you need to set the range function of the array element to two ranges and merge the arrays of the two detected elements into one space.  \n",
    "- This is where the merge array function is used, which is used when merging arrays of two different ranges.  \n",
    "\n",
    "â€» The array merge function can implement alpha blending, so you can display opaque blends of different images.\n",
    "\n",
    "â— ì˜ìƒì´ë‚˜ ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒì„ ê²€ì¶œ í•  ë•Œ, ë°°ì—´ ìš”ì†Œì˜ ë²”ìœ„ ì„¤ì • í•¨ìˆ˜(cv2.inRange)ë¡œ ìƒ‰ìƒì„ ì„¤ì •í•˜ëŠ” ë¶€ë¶„ì„ ì œí•œí• ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "- ì˜ˆë¥¼ ë“¤ì–´, ë¹¨ê°„ìƒ‰ ì˜ì—­ì„ ê²€ì¶œí•˜ë ¤ í•  ë•Œ, ë¹¨ê°„ìƒ‰ ì˜ì—­ì´ ì•½ 0 ~ 5ì™€ ì•½ 170 ~ 179ìœ¼ë¡œ ë²”ìœ„ê°€ ë‘ ê°€ì§€ë¡œ ë‚˜ëˆ ì ¸ ìˆìŠµë‹ˆë‹¤.  \n",
    "- ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´ ë°°ì—´ ìš”ì†Œì˜ ë²”ìœ„ ì„¤ì • í•¨ìˆ˜ë¥¼ ë‘ ê°œì˜ ë²”ìœ„ë¡œ ì„¤ì •í•˜ê³  ê²€ì¶œí•œ ë‘ ìš”ì†Œì˜ ë°°ì—´ì„ ë³‘í•©í•´ì„œ í•˜ë‚˜ì˜ ê³µê°„ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.  \n",
    "- ì´ë•Œ ë°°ì—´ ë³‘í•© í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©°, ì„œë¡œ ë‹¤ë¥¸ ë‘ ë²”ìœ„ì˜ ë°°ì—´ì„ ë³‘í•©í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "\n",
    "â€» ë°°ì—´ ë³‘í•© í•¨ìˆ˜ëŠ” ì•ŒíŒŒ ë¸”ë Œë”©(alpha blending)ì„ êµ¬í˜„í•  ìˆ˜ ìˆì–´ ì„œë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ë¶ˆíˆ¬ëª…í•˜ê²Œ í˜¼í•©í•´ì„œ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ Example:  \n",
    "* The red area is divided into two parts, ranging from 0 - 5 and 170 - 179.  \n",
    "* The array element range setting function allows you to set the range even for multi-channel images at once.  \n",
    "* Merges two color-separated arrays into one of two arrays entered by the array merge function (cv2.addWeighted).  \n",
    ">* **dst = cv2.addWeighted(src1, alpha, src2, beta, gamma, dtype = None)**:\n",
    ">- Calculate the sum of the product of weight1 (alpha) for input image1 (src1) and weight2 (beta) product for input image2 (src2) plus an additional sum (gamma).  \n",
    ">- Precision (dtype) sets the precision of the output image (dst), and if not assigned, it is assigned with the same precision as input image1.  \n",
    "\n",
    "* Since the two images will be combined as they are, the values of weight 1 and weight 2 will be used as 1.0, and 0.0 will be assigned as no additional sum will be used.    \n",
    "\n",
    "\n",
    "    * ë¹¨ê°„ìƒ‰ ì˜ì—­ì€ 0 ~ 5, 170 ~ 179ì˜ ë²”ìœ„ë¡œ ë‘ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ìˆìŠµë‹ˆë‹¤.  \n",
    "    * ë°°ì—´ ìš”ì†Œ ë²”ìœ„ ì„¤ì • í•¨ìˆ˜ëŠ” ë‹¤ì±„ë„ ì´ë¯¸ì§€ë„ í•œ ë²ˆì— ë²”ìœ„ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "    * ìƒ‰ìƒì„ ë¶„ë¦¬í•œ ë‘ ë°°ì—´ì„ ë°°ì—´ ë³‘í•© í•¨ìˆ˜(cv2.addWeighted)ë¡œ ì…ë ¥ëœ ë‘ ë°°ì—´ì˜ í•˜ë‚˜ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.  \n",
    "\n",
    "    * dst = cv2.addWeighted(src1, alpha, src2, beta, gamma, dtype = None):\n",
    "    - ì…ë ¥ ì´ë¯¸ì§€1(src1)ì— ëŒ€í•œ ê°€ì¤‘ì¹˜1(alpha) ê³±ê³¼ ì…ë ¥ ì´ë¯¸ì§€2(src2)ì— ëŒ€í•œ ê°€ì¤‘ì¹˜2(beta) ê³±ì˜ í•©ì— ì¶”ê°€ í•©(gamma)ì„ ë”í•´ì„œ ê³„ì‚°í•©ë‹ˆë‹¤.  \n",
    "    - ì •ë°€ë„(dtype)ì€ ì¶œë ¥ ì´ë¯¸ì§€(dst)ì˜ ì •ë°€ë„ë¥¼ ì„¤ì •í•˜ë©°, í• ë‹¹í•˜ì§€ ì•Šì„ ê²½ìš°, ì…ë ¥ ì´ë¯¸ì§€1ê³¼ ê°™ì€ ì •ë°€ë„ë¡œ í• ë‹¹ë©ë‹ˆë‹¤.  \n",
    "\n",
    "    * ë‘ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ í•©ì¹  ì˜ˆì •ì´ë¯€ë¡œ, ê°€ì¤‘ì¹˜1ê³¼ ê°€ì¤‘ì¹˜2ì˜ ê°’ì€ 1.0ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ì¶”ê°€ í•©ì€ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ 0.0ì„ í• ë‹¹í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"./images/practice_img/hsv1.webp\", cv2.IMREAD_COLOR)\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "lower_red = cv2.inRange(hsv, (0, 100, 100), (5, 255, 255))\n",
    "upper_red = cv2.inRange(hsv, (170, 100, 100), (180, 255, 255))\n",
    "added_red = cv2.addWeighted(lower_red, 0.1, upper_red, 1.0, 0.0)\n",
    "\n",
    "red = cv2.bitwise_and(hsv, hsv, mask = added_red)\n",
    "red = cv2.cvtColor(red, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow(\"red\", red)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(red, cv2.COLOR_BGR2RGB)),plt.title('addWeighted ')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ YUV or YCbCr  \n",
    "\n",
    "The YUV method is also known as the YCbCr method, \n",
    "- It is a type of color space used in imaging systems. Y is the luminance component, and Cb and Cr are the chrominance components.\n",
    "- Y is the brightness (Luma), Luminance refers to the amount of light reflected off the target object - the degree of glare, Luma is a normalization of luminance.\n",
    "- U is the difference between brightness and color with blue (Chroma Blue, Cb), \n",
    "- V stands for brightness and color difference from red (Chroma Red, Cr). \n",
    "It has the effect of compressing data by assigning a large number of bits to Y (brightness) and a small number of bits to U (Cb) and V (Cr). \n",
    "\n",
    "    YUV ë°©ì‹ì€ YCbCr ë°©ì‹ì´ë¼ê³ ë„ í•˜ë©°, \n",
    "    - ì˜ìƒ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë˜ëŠ” ìƒ‰ê³µê°„ì˜ ì¼ì¢…ì´ë‹¤. YëŠ” íœ˜ë„ ì„±ë¶„ì´ë©° Cb ì™€ Cr ì€ ìƒ‰ì°¨ ì„±ë¶„ì´ë‹¤.\n",
    "    - YëŠ” ë°ê¸°(Luma), íœ˜ë„ (Luminance)ëŠ” ëŒ€ìƒ ë¬¼ì²´ì— ë°˜ì‚¬ë˜ëŠ” ë¹›ì˜ ì–‘-ëˆˆë¶€ì‹¬ì˜ ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, LumaëŠ” Luminanceë¥¼ ì •ê·œí™” í•œê²ƒ\n",
    "    - UëŠ” ë°ê¸°ì™€ íŒŒë€ìƒ‰ê³¼ì˜ ìƒ‰ìƒ ì°¨(Chroma Blue, Cb), ì²­ìƒ‰ ì°¨ë¶„ ì±„ë„ ì„±ë¶„ \n",
    "    - VëŠ” ë°ê¸°ì™€ ë¹¨ê°„ìƒ‰ê³¼ì˜ ìƒ‰ìƒ ì°¨(Chroma Red, Cr)ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì ìƒ‰ ì°¨ë¶„ ì±„ë„ ì„±ë¶„ \n",
    "    Y(ë°ê¸°)ì—ëŠ” ë§ì€ ë¹„íŠ¸ìˆ˜ë¥¼ í• ë‹¹í•˜ê³  U(Cb)ì™€ V(Cr)ì—ëŠ” ì ì€ ë¹„íŠ¸ìˆ˜ë¥¼ í• ë‹¹í•˜ì—¬ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ëŠ” íš¨ê³¼ë¥¼ ê°–ìŠµë‹ˆë‹¤. \n",
    "\n",
    "<img src = './images/Y_0.5.png' width=200 height=100>\n",
    "\n",
    "<center>Y=0.5</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgr2yuv.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "dark = np.array([[[0,0,0]]], dtype=np.uint8)        # all 3 chnl =  0\n",
    "middle = np.array([[[127,127,127]]], dtype=np.uint8) # all 3 chnl =  127\n",
    "bright = np.array([[[255,255,255]]], dtype=np.uint8) # all 3 chnl =  255\n",
    "\n",
    "dark_yuv = cv2.cvtColor(dark, cv2.COLOR_BGR2YUV) # YUV\n",
    "middle_yuv = cv2.cvtColor(middle, cv2.COLOR_BGR2YUV)\n",
    "bright_yuv = cv2.cvtColor(bright, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "print(\"YUV_dark:\",dark_yuv)\n",
    "print(\"YUV_middle:\", middle_yuv)\n",
    "print(\"YUV_bright\", bright_yuv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â— The BGR values are (0, 0, 0), (127, 127, 127), (255, 255, 255), which are the darkest pixels, the medium-brightness pixels, and the brightest pixels.  -> If we convert them to YUV methods, they are (0, 128, 128), (127, 128, 128), and (255, 128, 128), respectively.   \n",
    "- the first value, Y, means brightness.   \n",
    "- The second and third values are the same, but only the Y values are changed to 0, 127, and 255.   \n",
    "- In other words, you can see that it converts from dark to light.\n",
    "\n",
    "â— BGRê°’ì€ (0, 0, 0), (127, 127, 127), (255, 255, 255)ë¡œ ì–´ë‘ìš´ í”½ì…€, ì¤‘ê°„ ë°ê¸°ì˜ í”½ì…€, ê°€ì¥ ë°ì€ í”½ì…€ì…ë‹ˆë‹¤.  -> ì´ë¥¼ YUV ë°©ì‹ìœ¼ë¡œ ë³€í™˜í•˜ë©´ ê°ê° (0, 128, 128), (127, 128, 128), (255, 128, 128)ì…ë‹ˆë‹¤.   \n",
    "- ë§¨ ì²˜ìŒ ê°’ì¸ Yê°€ ë°ê¸°ë¥¼ ëœ»í•œë‹¤ê³  í–ˆìŠµë‹ˆë‹¤.   \n",
    "- ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸ ê°’ì€ ë™ì¼í•œë° Yê°’ë§Œ 0, 127, 255ë¡œ ë°”ë€ë‹ˆë‹¤.   \n",
    "- ì¦‰ ì–´ë‘ìš´ ê°’ì—ì„œ ë°ì€ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "â€» If you need to pay more attention to brightness, it is wiser to use the YUV method rather than the BGR method  \n",
    "\n",
    "    â€» ë°ê¸°ì— ì¢€ ë” ì‹ ê²½ì„ ì¨ì•¼ í•œë‹¤ë©´ BGR ë°©ì‹ë³´ë‹¤ YUV ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” í˜„ëª…í•œ ë°©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–  To sum it up, there are four ways to express colors in OpenCV.  \n",
    "\n",
    "- BGR method, BGRA method, HSV method, YUV method. \n",
    "- The BGR method is similar to the traditional RGB method, only the order is reversed. \n",
    "- The BGRA method is a method in which an A (alpha) value indicating transparency is added in the BGR method. \n",
    "- The HSV method uses hue, saturation, and brightness to express colors, and if you know H, you can grasp the hue to some extent. Therefore, if you want to know the hue at a glance, you can use the HSV method. \n",
    "- The YUV method is great when you need to pay more attention to brightness.\n",
    "\n",
    "    â–  ìš”ì•½í•˜ë©´ OpenCVì—ì„œ ìƒ‰ìƒì„ í‘œí˜„í•˜ëŠ” ë°©ì‹ì€ ë„¤ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "    - BGR ë°©ì‹, BGRA ë°©ì‹, HSV ë°©ì‹, YUV ë°©ì‹ì…ë‹ˆë‹¤. \n",
    "    - BGR ë°©ì‹ì€ ì „í†µì ì¸ RGB ë°©ì‹ê³¼ ìœ ì‚¬í•˜ë©° ê·¸ ìˆœì„œë§Œ ë°˜ëŒ€ì…ë‹ˆë‹¤. \n",
    "    - BGRA ë°©ì‹ì€ BGR ë°©ì‹ì—ì„œ íˆ¬ëª…ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” A(ì•ŒíŒŒ) ê°’ì´ ì¶”ê°€ëœ ë°©ì‹ì…ë‹ˆë‹¤. \n",
    "    - HSV ë°©ì‹ì€ ìƒ‰ì¡°, ì±„ë„, ëª…ë„ë¥¼ ì´ìš©í•´ì„œ ìƒ‰ìƒì„ í‘œí˜„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ Hë§Œ ì•Œë©´ ìƒ‰ì¡°ëŠ” ì–´ëŠ ì •ë„ íŒŒì•…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ìƒ‰ì¡°ë¥¼ í•œëˆˆì— ì•Œê³ ì í•œë‹¤ë©´ HSV ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. \n",
    "    - YUV ë°©ì‹ì€ ë°ê¸°ì— ë” ì‹ ê²½ì„ ì¨ì•¼ í•˜ëŠ” ê²½ìš°ì— ì‚¬ìš©í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Color space code  \n",
    "\n",
    "https://www.rapidtables.com/web/color/RGB_Color.html\n",
    "\n",
    "|Code       |color space     |remarks  \n",
    "--------|-------|------\n",
    "|BGR|Blue, Green, Red channel|-\n",
    "|BGRA|Blue, Green, Red, Alpha channel|-\n",
    "|RGB|Red, Green, Blue channel|-\n",
    "|RGBA|Red, Green, Blue, Alpha channel|-\n",
    "|GRA|Single channel|ê·¸ë ˆì´ìŠ¤ì¼€ì¼\n",
    "|BGR565|Blue, Green, Red channel|16 ë¹„íŠ¸ ì´ë¯¸ì§€\n",
    "|XYZ|X, Y, Z channel|CIE 1931 ìƒ‰ ê³µê°„\n",
    "|YCrCb|Y, Cr, Cb channel|YCC (í¬ë¡œë§ˆ)\n",
    "|HSV|Hue, Saturation, Value channel|ìƒ‰ìƒ, ì±„ë„, ëª…ë„\n",
    "|Lab|L, a, b channel|ë°˜ì‚¬ìœ¨, ìƒ‰ë„1, ìƒ‰ë„2\n",
    "|Luv|L, u, v channel|CIE Luv\n",
    "|HLS|Hue, Lightness, Saturation channel|ìƒ‰ìƒ, ë°ê¸°, ì±„ë„\n",
    "|YUV|Y, U, V channel|ë°ê¸°, ìƒ‰ìƒ1, ìƒ‰ìƒ2\n",
    "|BG, GB, RG|Demosaicing|Single color ê³µê°„ìœ¼ë¡œ ë³€ê²½\n",
    "|_EA|Demosaicing|Edge Recognition\n",
    "|_VNG|Demosaicing|Using gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â§ RGBW, and WRGB\n",
    "https://www.coolblue.nl/en/advice/pixel-structure-televisions.html  \n",
    "    \n",
    "The screen of a 4K (UHD) television features an RGB, RGBW, or WRGB pixel structure.   \n",
    "Each screen has the same number of pixels, but produces color in different ways.   \n",
    "- An RGBW structure contains both colored and white pixels, for example.    \n",
    "\n",
    "### Â§ RGB Tv Sceeen  \n",
    "\n",
    "A TV screen is actually a grid that's made up of a fixed number of pixels per resolution.   \n",
    "- A 4K screen is 3,840 pixels high and 2,160 pixel wide, for example.   \n",
    "- In total, this numbers of 8 million pixels.   \n",
    "- An RGB television fills this grid with rows that consist of 3 pixel colors: red, green, and blue.   \n",
    "- These rows are repeated until the entire screen is filled.   \n",
    "- Because each pixel produces a color, the color representation is sharp and realistic.  \n",
    "\n",
    "### Â§ RGBW Tv Sceeen  \n",
    "\n",
    "With a RGBW screen, each row of 3 colored pixels is alternated with a white pixel.   \n",
    "- This means that 25% of the screen is made up of color, but of white light.   \n",
    "- If you exclude all of these white pixels, the television actually has a resolution of 2,880 by 2,160 pixels.   \n",
    "- This results in a less realistic color representation and less sharp screen, compared to an RGB television.  \n",
    "\n",
    "### Â§ WRGB Tv Sceeen  \n",
    "\n",
    "An OLED screen has its own pixel structure, which is called WRGB.   \n",
    "- This doesn't have rows with various pixels like RGBW does, but every pixel is the same.   \n",
    "- These pixels can produce colored and white light individually.   \n",
    "- That's because each pixel consists of red, green, blue, and white subpixels that are stacked.   \n",
    "- Thanks to a filter, it only lets through the desired colors.   \n",
    "- This technology ensures an extra accurate color representation.   \n",
    "- The disadvantage of this technology is that the colors become a bit dull with a high brightness.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7_YOLO",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
